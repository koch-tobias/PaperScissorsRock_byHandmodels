{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model engineering - Part: Transfer Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Research question**\n",
    "Can transfer learning bring a benefit on the performance of CNN models for Rock, Paper, Scissors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:** </br>\n",
    "Code according to: [learnpytorch.io](https://www.learnpytorch.io/05_pytorch_going_modular/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from timeit import default_timer as timer \n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "import random\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dir: str, \n",
    "                            test_dir: str, \n",
    "                            transform: transforms.Compose, \n",
    "                            batch_size: int, \n",
    "                            num_workers: int=1\n",
    "                        ):\n",
    "    \n",
    "    # Use ImageFolder to create dataset(s)\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "   \n",
    "    # Get class names\n",
    "    class_names = train_data.classes\n",
    "\n",
    "    # Turn images into data loaders\n",
    "    train_dataloader = DataLoader(train_data,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=num_workers,\n",
    "                                    pin_memory=True\n",
    "                                )\n",
    "    test_dataloader = DataLoader(test_data,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=num_workers,\n",
    "                                    pin_memory=True\n",
    "                                )\n",
    "\n",
    "    return train_dataloader, test_dataloader, class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_efficientNet_B0():\n",
    "\n",
    "    # Load best available weights from pretraining on ImageNet\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "    \n",
    "    # Load pretrained model with selected weights\n",
    "    model = torchvision.models.efficientnet_b0(weights=weights)\n",
    "\n",
    "    return model, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_dir: str, test_dir: str, weights, num_workers: int, batch_size: int):\n",
    "    # Get the transforms used to create our pretrained weights\n",
    "    auto_transforms = weights.transforms()\n",
    "\n",
    "    # Create training and testing DataLoaders as well as get a list of class names\n",
    "    train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir=train_dir,\n",
    "                                                                                test_dir=test_dir,\n",
    "                                                                                transform=auto_transforms, # perform same data transforms on our own data as the pretrained model\n",
    "                                                                                batch_size=batch_size, # set mini-batch size to 32\n",
    "                                                                                num_workers=num_workers) \n",
    "\n",
    "\n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to recreate the classifier layer of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_classifier_layer(model: torch.nn.Module, dropout: int, class_names: list):\n",
    "    # Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
    "    #for param in model.features.parameters():\n",
    "     #   param.requires_grad = False\n",
    "\n",
    "    # Set the manual seeds\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Recreate the classifier layer\n",
    "    model.classifier = torch.nn.Sequential(\n",
    "                            torch.nn.Dropout(p=dropout, inplace=True), \n",
    "                            torch.nn.Linear(in_features=1280, \n",
    "                            out_features=len(class_names), # one output unit for each class\n",
    "                            bias=True))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to train the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "                    dataloader: torch.utils.data.DataLoader, \n",
    "                    loss_fn: torch.nn.Module, \n",
    "                    optimizer: torch.optim.Optimizer\n",
    "                ) -> Tuple[float, float]:\n",
    "\n",
    "  # Put model in train mode\n",
    "  model.train()\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader data batches\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "      # 1. Forward pass\n",
    "      y_pred = model(X)\n",
    "\n",
    "      # 2. Calculate  and accumulate loss\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item() \n",
    "\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backward\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "\n",
    "      # Calculate and accumulate accuracy metric across all batches\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module\n",
    "              ) -> Tuple[float, float]:\n",
    "\n",
    "  # Put model in eval mode\n",
    "  model.eval() \n",
    "\n",
    "  # Setup test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  with torch.inference_mode():\n",
    "      # Loop through DataLoader batches\n",
    "      for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "          # 1. Forward pass\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          # 2. Calculate and accumulate loss\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "\n",
    "          # Calculate and accumulate accuracy\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "  # Adjust metrics to get average loss and accuracy per batch \n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module, \n",
    "            train_dataloader: torch.utils.data.DataLoader, \n",
    "            test_dataloader: torch.utils.data.DataLoader, \n",
    "            optimizer: torch.optim.Optimizer,\n",
    "            loss_fn: torch.nn.Module,\n",
    "            epochs: int,\n",
    "            folderpath: str\n",
    "            ) -> Dict[str, List]:\n",
    "\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "                \"train_acc\": [],\n",
    "                \"test_loss\": [],\n",
    "                \"test_acc\": []\n",
    "            }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                            dataloader=train_dataloader,\n",
    "                                            loss_fn=loss_fn,\n",
    "                                            optimizer=optimizer\n",
    "                                            )\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn\n",
    "            )\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "    model_folder = store_model(folderpath, model, results)\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results, model_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_model(folderpath: Path, classifier_model:torch.nn.Module, results:dict):\n",
    "    logger.info(\"Store model...\")\n",
    "    model_path = folderpath / (\"model.pkl\")\n",
    "    results_path = folderpath / (\"results.pkl\")\n",
    "\n",
    "    with open(model_path, \"wb\") as filestore:\n",
    "        pickle.dump(classifier_model, filestore)\n",
    "\n",
    "    with open(results_path, \"wb\") as filestore:\n",
    "        pickle.dump(results, filestore)\n",
    "\n",
    "    logger.info(\"Model stored!\")\n",
    "\n",
    "    return folderpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create a folder for the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_storage_name(targetfolder:str, model_name:str):\n",
    "    dateTimeObj = datetime.now()\n",
    "    timestampStr = dateTimeObj.strftime(\"%d%m%Y_%H%M\")\n",
    "    folderpath = Path(targetfolder + \"/\" + model_name + \"_model\" + \"_\" + timestampStr)\n",
    "    folderpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return folderpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to store the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_hyperparameters(target_dir_new_model:str,model_name:str, dict:dict):\n",
    "    folderpath = get_storage_name(target_dir_new_model, model_name)\n",
    "    \n",
    "    dict_path = folderpath / (\"hyperparameter_dict.pkl\")\n",
    "    with open(dict_path, \"wb\") as filestore:\n",
    "        pickle.dump(dict, filestore)\n",
    "    return folderpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_folder: str):\n",
    "    onlyfiles = [f for f in listdir(model_folder) if isfile(join(model_folder, f))]\n",
    "\n",
    "    model_path = model_folder / onlyfiles[1]\n",
    "    results_path = model_folder / onlyfiles[2]\n",
    "    hyperparameters_path = model_folder / onlyfiles[0]\n",
    "\n",
    "    with open(model_path, \"rb\") as fid:\n",
    "        classifier_model = pickle.load(fid)\n",
    "\n",
    "    with open(results_path, \"rb\") as fid:\n",
    "        results = pickle.load(fid)\n",
    "\n",
    "    with open(hyperparameters_path, \"rb\") as fid:\n",
    "        dict = pickle.load(fid)\n",
    "\n",
    "    logger.info(\"Model and hyperparameters loaded!\")\n",
    "\n",
    "    return classifier_model, results, dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for plotting the loss curve and the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(results):\n",
    "    \"\"\"Plots training curves of a results dictionary.\n",
    "    Args:\n",
    "        results (dict): dictionary containing list of values, e.g.\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"test_loss\"]\n",
    "\n",
    "    accuracy = results[\"train_acc\"]\n",
    "    test_accuracy = results[\"test_acc\"]\n",
    "\n",
    "    epochs = range(len(results[\"train_loss\"]))\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label=\"train_loss\")\n",
    "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
    "    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to make predictions on validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_plot_image(model: torch.nn.Module,\n",
    "                            image_path: str,\n",
    "                            class_names: List[str] = None,\n",
    "                            transform=None,\n",
    "                            ax=None):\n",
    "\n",
    "    # Load in image and convert the tensor values to float32\n",
    "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
    "\n",
    "    # Divide the image pixel values by 255 to get them between [0, 1]\n",
    "    target_image = target_image / 255\n",
    "\n",
    "    # Transform if necessary\n",
    "    if transform:\n",
    "        target_image = transform(target_image)\n",
    "\n",
    "    # Turn on model evaluation mode and inference mode\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Add an extra dimension to the image\n",
    "        target_image = target_image.unsqueeze(dim=0)\n",
    "\n",
    "        # Make a prediction on image with an extra dimension and send it to the target device\n",
    "        target_image_pred = model(target_image)\n",
    "\n",
    "    # Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "\n",
    "    # Convert prediction probabilities -> prediction labels\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "\n",
    "    if ax is None:\n",
    "        # Plot the image alongside the prediction and prediction probability\n",
    "        plt.imshow(\n",
    "            target_image.squeeze().permute(1, 2, 0)\n",
    "        )  # make sure it's the right size for matplotlib\n",
    "        if class_names:\n",
    "            title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
    "        else:\n",
    "            title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
    "        plt.title(title)\n",
    "        plt.axis(False)\n",
    "    else:\n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                            bottom=0.1,\n",
    "                            right=0.45,\n",
    "                            top=0.5,\n",
    "                            wspace=0.4,\n",
    "                            hspace=0.4)\n",
    "        # Plot the image alongside the prediction and prediction probability\n",
    "        ax.imshow(\n",
    "            target_image.squeeze().permute(1, 2, 0)\n",
    "        )  # make sure it's the right size for matplotlib\n",
    "        if class_names:\n",
    "            title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
    "        else:\n",
    "            title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
    "        ax.set_title(title)\n",
    "        ax.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_TransferLearning_model(dataset_path:str, seed:int, learning_rate:float, epochs:int, dropout:float, num_workers:int, batch_size:int):\n",
    "    train_dir = dataset_path + \"/train\"\n",
    "    test_dir = dataset_path + \"/test\"\n",
    "    target_dir_new_model = '../models'\n",
    "    model_name = \"TransferLearning\"\n",
    "\n",
    "    dict_hyperparameters = {'seed': seed, 'learning_rate':learning_rate, 'epochs': epochs, \n",
    "                        'dropout':dropout, 'num_workers':num_workers,'batch_size': batch_size}\n",
    "\n",
    "    folderpath = store_hyperparameters(target_dir_new_model,model_name=model_name,dict=dict_hyperparameters)\n",
    "\n",
    "    # Load pretrained model, weights and the transforms\n",
    "    model, weights = load_pretrained_efficientNet_B0()\n",
    "\n",
    "    # Load data\n",
    "    train_dataloader, test_dataloader, class_names = load_data(train_dir=train_dir,\n",
    "                                                                    test_dir=test_dir, \n",
    "                                                                    weights=weights, \n",
    "                                                                    num_workers=num_workers, \n",
    "                                                                    batch_size=batch_size)\n",
    "\n",
    "    # Recreate classifier layer\n",
    "    model = recreate_classifier_layer(model=model, \n",
    "                                            dropout=dropout, \n",
    "                                            class_names=class_names)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Set the random seeds\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = timer()\n",
    "\n",
    "    # Setup training and save the results\n",
    "    results, model_folder = train(model=model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=epochs,\n",
    "                        folderpath=folderpath\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "    # End the timer and print out how long it took\n",
    "    end_time = timer()\n",
    "\n",
    "    time.sleep(10)\n",
    "    print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
    "    plot_loss_curves(results)\n",
    "    \n",
    "    return model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_existing_model(model_folder:str,validation_folder:str, num_images:int):\n",
    "\n",
    "    trained_model, model_results, dict_hyperparameters = get_model(Path(model_folder))\n",
    "\n",
    "    plot_loss_curves(model_results)\n",
    "\n",
    "    # Make predictions on random images from validation dataset\n",
    "    val_dir = \"../data_combined/dataset_splitted/val\"\n",
    "    class_names = ['paper', 'rock', 'scissors']\n",
    "\n",
    "    weights = torchvision.models.EfficientNet_V2_L_Weights.DEFAULT\n",
    "    auto_transforms = weights.transforms()\n",
    "\n",
    "    valid_image_path_list = list(Path(validation_folder).glob(\"*/*.*\")) # get list all image paths from test data \n",
    "    valid_image_path_sample = random.sample(population=valid_image_path_list, # go through all of the test image paths\n",
    "                                        k=num_images) # randomly select 'k' image paths to pred and plot\n",
    "\n",
    "    font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "    fig, axes = plt.subplots(math.ceil(num_images/2),2, figsize=(15,15))\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    # Make predictions on and plot the images\n",
    "    for image_path, ax in zip(valid_image_path_sample,axes.ravel()):\n",
    "        pred_and_plot_image(model=trained_model, \n",
    "                            image_path=image_path,\n",
    "                            class_names=class_names,\n",
    "                            transform=auto_transforms,\n",
    "                            ax = ax)\n",
    "    if num_images%2 != 0:\n",
    "        fig.delaxes(axes[math.ceil(num_images/2)-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_on_single_image(image_path:str, model_folder:str):\n",
    "    class_names = ['paper', 'rock', 'scissors']\n",
    "\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "    auto_transforms = weights.transforms()\n",
    "\n",
    "    trained_model, model_results, dict_hyperparameters = get_model(Path(model_folder))\n",
    "\n",
    "\n",
    "    pred_and_plot_image(trained_model, image_path, class_names, auto_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main-method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__getattr__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb Zelle 34\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m prediction_on_single_image \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mif\u001b[39;00m train_new_transferlearning_model:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     model_folder \u001b[39m=\u001b[39m train_new_TransferLearning_model(dataset_path\u001b[39m=\u001b[39;49mdataset_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                                                         seed\u001b[39m=\u001b[39;49mseed, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m                                                         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                                                         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                                                         dropout\u001b[39m=\u001b[39;49mdropout,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                                                         num_workers\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m                                                         batch_size\u001b[39m=\u001b[39;49mbatch_size)  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     eval_existing_model(model_folder\u001b[39m=\u001b[39mmodel_folder, validation_folder\u001b[39m=\u001b[39mvalidation_folder, num_images\u001b[39m=\u001b[39mnum_images_val)  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mif\u001b[39;00m evaluate_existing_model:\n",
      "\u001b[1;32m/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb Zelle 34\u001b[0m in \u001b[0;36mtrain_new_TransferLearning_model\u001b[0;34m(dataset_path, seed, learning_rate, epochs, dropout, num_workers, batch_size)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Define loss and optimizer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Set the random seeds\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Tobi/Desktop/Master_WINF_OFU/PaperScissorRock_byHandmodels/dev_notebooks/dev_model_engineering_transferLearning.ipynb#X45sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(seed)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/envPaperScissorsRock/lib/python3.8/site-packages/torchvision/models/_api.py:76\u001b[0m, in \u001b[0;36mWeightsEnum.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m name:\n\u001b[1;32m     75\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue, name)\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__getattr__'"
     ]
    }
   ],
   "source": [
    "# Define dataset path\n",
    "dataset_path = '../data_combined/dataset_splitted'\n",
    "model_folder = \"../models/model_08112022_2233\"\n",
    "validation_folder = \"../data_combined/dataset_splitted/val\"\n",
    "single_image_path = \"../data_own_images/paper_Tobi.jpg\"\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "seed = 42\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "dropout = 0.2\n",
    "num_workers = 2\n",
    "batch_size = 32\n",
    "num_images_val = 6\n",
    "\n",
    "# Set if you want to train a new model or evualate an existing model\n",
    "train_new_transferlearning_model = True\n",
    "train_new_baseline_model = False\n",
    "evaluate_existing_model = False\n",
    "prediction_on_single_image = False\n",
    "\n",
    "if train_new_transferlearning_model:\n",
    "    model_folder = train_new_TransferLearning_model(dataset_path=dataset_path,\n",
    "                                                        seed=seed, \n",
    "                                                        learning_rate=learning_rate,\n",
    "                                                        epochs=epochs,\n",
    "                                                        dropout=dropout,\n",
    "                                                        num_workers=num_workers,\n",
    "                                                        batch_size=batch_size)  \n",
    "    eval_existing_model(model_folder=model_folder, validation_folder=validation_folder, num_images=num_images_val)  \n",
    "\n",
    "if evaluate_existing_model:\n",
    "    eval_existing_model(model_folder=model_folder, validation_folder=validation_folder, num_images=num_images_val)\n",
    "\n",
    "if prediction_on_single_image:\n",
    "    pred_on_single_image(image_path=single_image_path, model_folder=model_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('envPaperScissorsRock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "246e1f8a7853b7843a5a4bae4dd15b195eef0a7489bca88a3b586940aa1ce5a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
